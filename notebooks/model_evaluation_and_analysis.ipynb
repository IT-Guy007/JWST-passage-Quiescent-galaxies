{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "project_directory = os.path.dirname(os.getcwd())\n",
    "data_directory = os.path.join(project_directory, \"data\")\n",
    "dataset_directory = os.path.join(project_directory, \"tf_data\")\n",
    "model_directory = os.path.join(project_directory, \"models\")\n",
    "model_name = \"model_v1\" # Change this\n",
    "\n",
    "img_height = 200\n",
    "img_width = 200\n",
    "batch_size = 32\n",
    "\n",
    "class_names = sorted([name for name in os.listdir(dataset_directory) if os.path.isdir(os.path.join(dataset_directory, name))])"
   ],
   "id": "a54020b7dad6f21e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load data",
   "id": "c4cfc7f07aa4661c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = tf.keras.models.load_model(os.path.join(model_directory, f'{model_name}.keras'))\n",
    "with open(os.path.join(model_directory, f'{model_name}_history.json'), 'r') as f:\n",
    "    history = json.load(f)"
   ],
   "id": "9a2562e36918a427",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a summary of the layers and training parameters",
   "id": "b96cebcb409997bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.summary()",
   "id": "514ff9475cb21828",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Plot training & validation loss values",
   "id": "95e601a8afb186ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ],
   "id": "36516549c3d2741",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create classification report",
   "id": "914e9bb1e02db78"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "random_seat = 123\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    dataset_directory,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "for images, labels in val_ds:\n",
    "    predictions = model.predict(images)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(predictions, axis=1))\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "print(report)"
   ],
   "id": "e507b6d6d735daf6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Plot first batch with predictions",
   "id": "9ba0b1976e8a8089"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "val_ds_shuffled = val_ds.shuffle(buffer_size=len(val_ds))\n",
    "\n",
    "for images, labels in val_ds_shuffled.take(1):\n",
    "    predictions = model.predict(images)\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(len(images)):\n",
    "        ax = plt.subplot(3, 4, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        predicted_class = np.argmax(predictions[i])\n",
    "        confidence = np.max(predictions[i])\n",
    "        true_label = class_names[labels[i]]\n",
    "        predicted_label = class_names[predicted_class]\n",
    "        color = \"green\" if predicted_label == true_label else \"red\"\n",
    "        plt.title(f\"True: {true_label}\\nPred: {predicted_label} ({confidence:.2f})\", color=color)\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ],
   "id": "30c6d9cf4c607ab5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creates predictions from a directory of test png images",
   "id": "1a7454ab9c30042f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_number(filename):\n",
    "    try:\n",
    "        return int(filename.split('.')[0][3:])\n",
    "    except ValueError:\n",
    "        return -1\n",
    "\n",
    "def plot_images_from_directory(model, directory, class_names, true_label, target_size=(img_height, img_width), save_to_dir=\"\"):\n",
    "    image_files = sorted(\n",
    "        [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.png') and file.startswith('obj')],\n",
    "        key=extract_number\n",
    "    )\n",
    "\n",
    "    \n",
    "    original_images = []\n",
    "    altered_images = []\n",
    "    \n",
    "    num_correct_predictions = 0  # Counter for correct predictions\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        try:\n",
    "            img = tf.keras.preprocessing.image.load_img(image_file, target_size=target_size)\n",
    "            img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "            original_images.append(img_array)\n",
    "            altered_img_array = alter_image(img_array)\n",
    "            altered_img_array = np.expand_dims(altered_img_array, axis=0)\n",
    "            altered_images.append(altered_img_array)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_file}: {e}\")\n",
    "    \n",
    "    if not altered_images:\n",
    "        print(\"No valid images found in the directory.\")\n",
    "        return\n",
    "    \n",
    "    altered_images = np.vstack(altered_images)\n",
    "    predictions = model.predict(altered_images)\n",
    "    \n",
    "    # Determine the subplot grid size\n",
    "    num_images = len(altered_images)\n",
    "    num_cols = 4\n",
    "    num_rows = (num_images + num_cols - 1) // num_cols\n",
    "    \n",
    "    plt.figure(figsize=(num_cols * 3, num_rows * 3 + 2))\n",
    "    plt.suptitle(f\"{os.path.basename(directory)}\", fontsize=16)\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        ax = plt.subplot(num_rows, num_cols, i + 1)\n",
    "        plt.imshow(altered_images[i].astype(\"uint8\"))\n",
    "        predicted_class = np.argmax(predictions[i])\n",
    "        confidence = np.max(predictions[i])\n",
    "        predicted_label = class_names[predicted_class]\n",
    "        \n",
    "        # Determine title color based on correctness of prediction\n",
    "        title_color = \"green\" if predicted_label == true_label else \"red\"\n",
    "        \n",
    "        # Update num_correct_predictions if prediction is correct\n",
    "        if predicted_label == true_label:\n",
    "            num_correct_predictions += 1\n",
    "        \n",
    "        plt.title(f\"Pred: {predicted_label} ({confidence:.2f})\", color=title_color)\n",
    "        plt.axis(\"off\")\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "    \n",
    "    # Calculate percentage of correct predictions\n",
    "    percentage_correct = (num_correct_predictions / num_images) * 100\n",
    "    \n",
    "    # Add percentage of correct predictions to the title\n",
    "    plt.suptitle(f\"{os.path.basename(directory)} - Correct Predictions: {percentage_correct:.2f}%\", fontsize=16)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "    \n",
    "    if len(save_to_dir) > 0:\n",
    "        plt.savefig(os.path.join(save_to_dir, f'{os.path.basename(directory)}.png'))\n",
    "    plt.show()"
   ],
   "id": "38e0a9ce56ba3e81",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
